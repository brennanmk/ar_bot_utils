{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This section contains code that will train a number of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:51:11\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ar_bot_gym.ar_bot_gym import ARBotGym\n",
    "from ar_bot_pybullet.ar_bot_pybullet import ARBotPybullet\n",
    "from stable_baselines_models.train_arbot import TrainARBot\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "NUM_EPISODES = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxed Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = gym.spaces.box.Box(\n",
    "            low=np.array([-0.5, -0.5]),\n",
    "            high=np.array([0.5, 0.5]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n"
     ]
    }
   ],
   "source": [
    "simple_ppo_boxed = TrainARBot(ARBotPybullet, ARBotGym, actions, PPO)\n",
    "simple_ppo_boxed_total_sum_reward_tracker, simple_ppo_boxed_total_timestep_tracker = simple_ppo_boxed.train(NUM_EPISODES, \"stable_baselines_models/trained_models/simple_ppo_boxed\", \"stable_baselines_models/training_data/simple_ppo_boxed.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'obstacles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m complex_ppo_boxed \u001b[38;5;241m=\u001b[39m TrainARBot(ARBotPybullet, ARBotGym, actions, PPO)\n\u001b[0;32m----> 2\u001b[0m complex_ppo_boxed_total_sum_reward_tracker, complex_ppo_boxed_total_timestep_tracker \u001b[38;5;241m=\u001b[39m \u001b[43mcomplex_ppo_boxed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstable_baselines_models/trained_models/complex_ppo_boxed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstable_baselines_models/training_data/complex_ppo_boxed.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobstacles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'obstacles'"
     ]
    }
   ],
   "source": [
    "complex_ppo_boxed = TrainARBot(ARBotPybullet, ARBotGym, actions, PPO)\n",
    "complex_ppo_boxed_total_sum_reward_tracker, complex_ppo_boxed_total_timestep_tracker = complex_ppo_boxed.train(NUM_EPISODES, \"stable_baselines_models/trained_models/complex_ppo_boxed\", \"stable_baselines_models/training_data/complex_ppo_boxed.npy\", obstacle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = gym.spaces.Discrete(4)\n",
    "\n",
    "action_mapping = {\n",
    "    0: (0.0, 0.5),\n",
    "    1: (0.5, 0.0),\n",
    "    2: (0.0, -0.5),\n",
    "    3: (-0.5, 0.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ppo_discrete = TrainARBot(ARBotPybullet, ARBotGym, actions, PPO, action_mapping)\n",
    "simple_ppo_discrete_total_sum_reward_tracker, simple_ppo_discrete_total_timestep_tracker = simple_ppo_discrete.train(NUM_EPISODES, \"stable_baselines_models/trained_models/simple_ppo_discrete\", \"stable_baselines_models/training_data/simple_ppo_discrete.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_ppo_discrete = TrainARBot(ARBotPybullet, ARBotGym, actions, PPO, action_mapping)\n",
    "complex_ppo_discrete_total_sum_reward_tracker, complex_ppo_discrete_total_timestep_tracker = complex_ppo_discrete.train(NUM_EPISODES, \"stable_baselines_models/trained_models/complex_ppo_discrete\", \"stable_baselines_models/training_data/complex_ppo_discrete.npy\", obstacle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiDiscrete Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = gym.spaces.MultiDiscrete([3, 3])\n",
    "\n",
    "action_mapping = {\n",
    "    0: -0.5,\n",
    "    1: 0,\n",
    "    2: 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ppo_multi_discrete = TrainARBot(ARBotPybullet, ARBotGym, actions, PPO, action_mapping)\n",
    "simple_ppo_multi_discrete_total_sum_reward_tracker, simple_ppo_multi_discrete_total_timestep_tracker = simple_ppo_multi_discrete.train(NUM_EPISODES, \"stable_baselines_models/trained_models/simple_ppo_multi_discrete\", \"stable_baselines_models/training_data/simple_ppo_multi_discrete.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_ppo_multi_discrete = TrainARBot(ARBotPybullet, ARBotGym, actions, PPO, action_mapping)\n",
    "complex_ppo_multi_discrete_total_sum_reward_tracker, complex_ppo_multi_discrete_total_timestep_tracker = complex_ppo_multi_discrete.train(NUM_EPISODES, \"stable_baselines_models/trained_models/complex_ppo_multi_discrete\", \"stable_baselines_models/training_data/complex_ppo_multi_discrete.npy\", obstacle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The importing of numpy is redandant if running in the same kernal used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse\n",
    "\n",
    "Parse the data contained in the npy files created during training above. \n",
    "\n",
    "This step can be safely skipped if running in the same kernal that training was completed in.\n",
    "\n",
    "Note that the file locations will needed to be tweaked if using a different training_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stable_baselines_models/training_data/ppo_boxed.npy\", \"rb\") as ppo_data:\n",
    "    ppo_total_sum_reward_tracker = np.load(ppo_data)\n",
    "    ppo_total_timestep_tracker = np.load(ppo_data)\n",
    "\n",
    "print(ppo_total_timestep_tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ppo_total_timestep_tracker, label=\"PPO\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sum of Rewards\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.title(\"Sum Of Rewards Across Episodes\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x=np.arange(ppo_total_sum_reward_tracker.shape[1]),y=ppo_total_sum_reward_tracker, label=\"PPO\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Sum of Rewards\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.title(\"Sum Of Rewards Across Episodes\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
